Este arquivo contém todos os tratamentos realizados com o dataset relativo às temperaturas médias no planeta -  fonte https://ourworldindata.org/
utilizado no Projeto Final de Engenharia de Dados c/ Python e Google Cloud da Soul Code Academy
feito e entregue pelo Grupo 5

# Pandas

Instalação do pacote gcsfs para acesso de arquivos direto do GCStorage

pip install gcsfs

Instalação do pacote Pandera para validação de dados

pip install pandera

Importação de biblioteca para autenticação da service account e uso dos arquivos do bucket GCP

import os

Importação de bibliotecas a serem utilizadas na etapa de tratamento pandas/pandera.

import pandas as pd
import pandera as pa
from google.cloud import storage


Montagem da pasta /drive para poder acessar a pasta /MyDrive e futuramente enviar/importar arquivos do bucket

from google.colab import drive
drive.mount('/content/drive')

Foi criada uma conta de serviço relacionada ao Bucket do CloudStorage bem como uma chave para interação entre as ferramentas. A seguir o arquivo de chave da conta de servico é atribuida a variável serviceAccount.

serviceAccount = '/content/projetofinal-grupo5-d2c4a9d78233.json'

os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = serviceAccount

Leitura do arquivo CSV utilizando o URI do arquivo no bucket.

client = storage.Client()
bucket = client.get_bucket('projeto-final-bucket-g5')
#a variável bucket recebe o nome identico do bucket do cloud storage
bucket.blob('Temperatura_media_pais.csv')
#a variável bucket_blob recebe o nome do arquivo
path = 'gs://projeto-final-bucket-g5/entrada/Temperatura_media_pais.csv'
# a variável path recebe o caminho do arquivo (URI) do arquivo
df_orig = pd.read_csv(path, parse_dates=['dt'])
#leitura do arquivo e método parse-date que pega uma string de data formatada customizada e a converte em uma string de dados formatada padrão do esquema XML (YYYY-MM-DD)

df_orig

#verificação do tipo do dado
df_orig.dtypes

Criação de um data frame de Backup

df = df_orig.copy()

df.head(1)

Lista países

df['Country'].unique()

Países para verificar:


Dropar: 'Aland', 'Africa', 'America Samoa', 'Asia', 'Baker Island', 'Bonaire', 'Saint Eustatius And Saba',
'Gongo', 'Dinamarka', 'Europa', 'France', 'French Southern And Antarctic Lands', 'Gaza Strip', 'Guam', 'Guernsey',
'Heard Island And Mcdonald Islands', 'Isle Of Man', 'Jersey', 'Kingman Reef', 'Mayotte', 'Monaco', 'Netherlands', 'North America',
'Northern Mariana Islands', 'Oceania', 'Palmyra Atoll', 'Puerto Rico', 'Saint Barthélemy','Saint Martin', 'Saint Pierre And Miquelon',
'San Marino',  'Sint Maarten', 'South America', 'South Georgia And The South Sandwich Isla', 'Svalbard And Jan Mayen','United Kingdom (Europe)',
'Virgin Islands', 'Western Sahara'
<br>
<br>
Trocar: 
* 'Burma' por 'Myanmar'
* "Côte D'Ivoire" por "Cote d'Ivoire"
* 'Curaçao' por 'Curacao'
* 'Denmark (Europe)' por 'Denmark'
* 'Falkland Islands (Islas Malvinas)' por 'Islas Malvinas'
* 'Federated States Of Micronesia' por 'Micronesia'
* 'France (Europe)' por 'France'
* 'Netherlands (Europe)' por 'Netherlands'
* 'United Kingdom (Europe)' por 'United Kingdom'
* 'Turks And Caicas Islands' por 'Turks And Caicos Islands'

Eliminar linhas de países que não coincidem com o dataset de emissão de CO2

# Dropar países

df.drop(df[(df['Country'] == 'Åland')].index, inplace=True)
df.drop(df[(df['Country'] == 'Africa')].index, inplace=True)
df.drop(df[(df['Country'] == 'American Samoa')].index, inplace=True)
df.drop(df[(df['Country'] == 'Asia')].index, inplace=True)
df.drop(df[(df['Country'] == 'Baker Island')].index, inplace=True)
df.drop(df[(df['Country'] == 'Bonaire, Saint Eustatius And Saba')].index, inplace=True)
df.drop(df[(df['Country'] == 'Denmark')].index, inplace=True)
df.drop(df[(df['Country'] == 'Europa')].index, inplace=True)
df.drop(df[(df['Country'] == 'France')].index, inplace=True)
df.drop(df[(df['Country'] == 'French Southern And Antarctic Lands')].index, inplace=True)
df.drop(df[(df['Country'] == 'Gaza Strip')].index, inplace=True)
df.drop(df[(df['Country'] == 'Guam')].index, inplace=True)
df.drop(df[(df['Country'] == 'Guernsey')].index, inplace=True)
df.drop(df[(df['Country'] == 'Heard Island And Mcdonald Islands')].index, inplace=True)
df.drop(df[(df['Country'] == 'Isle Of Man')].index, inplace=True)
df.drop(df[(df['Country'] == 'Jersey')].index, inplace=True)
df.drop(df[(df['Country'] == 'Kingman Reef')].index, inplace=True)
df.drop(df[(df['Country'] == 'Mayotte')].index, inplace=True)
df.drop(df[(df['Country'] == 'Monaco')].index, inplace=True)
df.drop(df[(df['Country'] == 'Netherlands')].index, inplace=True)
df.drop(df[(df['Country'] == 'North America')].index, inplace=True)
df.drop(df[(df['Country'] == 'Northern Mariana Islands')].index, inplace=True)
df.drop(df[(df['Country'] == 'Oceania')].index, inplace=True)
df.drop(df[(df['Country'] == 'Palmyra Atoll')].index, inplace=True)
df.drop(df[(df['Country'] == 'Puerto Rico')].index, inplace=True)
df.drop(df[(df['Country'] == 'Saint Barthélemy')].index, inplace=True)
df.drop(df[(df['Country'] == 'Saint Martin')].index, inplace=True)
df.drop(df[(df['Country'] == 'Saint Pierre And Miquelon')].index, inplace=True)
df.drop(df[(df['Country'] == 'San Marino')].index, inplace=True)
df.drop(df[(df['Country'] == 'Sint Maarten')].index, inplace=True)
df.drop(df[(df['Country'] == 'South America')].index, inplace=True)
df.drop(df[(df['Country'] == 'South Georgia And The South Sandwich Isla')].index, inplace=True)
df.drop(df[(df['Country'] == 'Svalbard And Jan Mayen')].index, inplace=True)
df.drop(df[(df['Country'] == 'United Kingdom')].index, inplace=True)
df.drop(df[(df['Country'] == 'Virgin Islands')].index, inplace=True)
df.drop(df[(df['Country'] == 'Western Sahara')].index, inplace=True)

df.loc[df['Country'] == 'Virgin Islands']

  Correção de nomes de países de acordo com a lista padrão

df.loc[df.Country == 'Burma' , ['Country']] = 'Myanmar'
df.loc[df.Country == "Côte D'Ivoire" , ['Country']] = "Cote d'Ivoire"
df.loc[df.Country == 'Curaçao' , ['Country']] = 'Curacao'
df.loc[df.Country == 'Denmark (Europe)' , ['Country']] = 'Denmark'
df.loc[df.Country == 'Falkland Islands (Islas Malvinas)' , ['Country']] = 'Islas Malvinas'
df.loc[df.Country == 'Federated States Of Micronesia' , ['Country']] = 'Micronesia'
df.loc[df.Country == 'France (Europe)' , ['Country']] = 'France'
df.loc[df.Country == 'Netherlands (Europe)' , ['Country']] = 'Netherlands'
df.loc[df.Country == 'United Kingdom (Europe)' , ['Country']] = 'United Kingdom'
df.loc[df.Country == 'Turks And Caicas Islands' , ['Country']] = 'Turks And Caicos Islands'

df.loc[df['Country'] == 'Myanmar']

Renomear / Traduzir colunas

(
df.rename(columns={'dt': 'Data', 'AverageTemperature': 'TemperaturaMedia', 
                   'AverageTemperatureUncertainty': 'CertitudeTempMedia', 'Country': 'País'}
                        , inplace=True) 
)

df.head(1)

df['País'].unique()

Novas mudanças de nomes de países

df.drop(df[(df['País'] == 'Europe')].index, inplace=True)

df.loc[df.País == 'Turks And Caicos Islands', ['País']] = 'Turks and Caicos Islands'
df.loc[df.País == 'Trinidad And Tobago', ['País']] = 'Trinidad and Tobago'
df.loc[df.País == 'Saint Vincent And The Grenadines', ['País']] = 'Saint Vincent and the Grenadines'
df.loc[df.País == 'Saint Kitts And Nevis', ['País']] = 'Saint Kitts and Nevis'
df.loc[df.País == 'Palestina', ['País']] = 'Palestine'
df.loc[df.País == 'Antigua And Barbuda', ['País']]  = ' Antigua and Barbuda '
df.loc[df.País == 'Bosnia And Herzegovina', ['País']]  = 'Bosnia and Herzegovina'
df.loc[df.País == 'Congo (Democratic Republic Of The)', ['País']] = 'Democratic Republic of the Congo'
df.loc[df.País == 'Guinea Bissau', ['País']]  = 'Guinea-Bissau'
df.loc[df.País == 'Macau', ['País']]  = 'Macao'

df['País'].unique()

Verificar dados nulos

df.isnull().sum()

Validação de dados com Pandera

schema = pa.DataFrameSchema(
    columns = {
        "Data": pa.Column(pa.DateTime,nullable=False),
        "TemperaturaMedia": pa.Column(pa.Float,nullable=True),
        "CertitudeTempMedia": pa.Column(pa.Float,nullable=True),
        "País": pa.Column(pa.String,nullable=False)})

schema.validate(df)

# Salvar o DF em CSV diretamente no bucket do GCP – versão tratada em Pandas

client=storage.Client()
bucket=client.get_bucket('projeto-final-bucket-g5')
bucket.blob('saida/df_temp_media_pandas_tratamento_final.csv').upload_from_string(df.to_csv(index=False), 'text/cvs')


# PYSPARK

Instalação da biblioteca Pyspark

pip install pyspark

Importação de módulos e de funções específicas dentro da biblioteca Pyspark

from pyspark.sql import SparkSession
#ParkSession é uma string de conexão, na qual serão definidos os devidos parâmetros
import pyspark.sql.functions as F
#importação da biblioteca de funções do pacote spark atribuindo F para o uso durante o código
from pyspark.sql.types import StructType,StructField, StringType, IntegerType, FloatType, DoubleType, DateType, ArrayType, DoubleType, BooleanType
#importação dos tipos de variaveis para futura estruturação e validação
from pyspark.sql.functions import col,array_contains
from pyspark.sql.window import Window
#importação de funções do tipo window

Configurando a SparkSession

spark = SparkSession.builder\
        .master("local")\ #master: local, cluester, ou local onde irá rodar a sessão
        .appName("dataframe_temperatura")\#identificaçao do aplicação a ser criad
        .config("spark.ui.port","4050")\#configurção via API com apache spark, e definção da porta UI, que no caso do colab é 4050
        .getOrCreate()#iniciar a sessão

Criando o Esquema/Schema com a função StructType, usando o dataframe já criado na etapa do Pandas. Aqui, apesar da validação feita anteriormente, é interessante o uso do StructType para grantir os tipos das variáveis no momento da criação do dataframe no pyspark, assim a efetuação de calculos e manipulações corretamente.

esquema = (
    StructType()
      .add("Data",DateType(),True)
      .add("TemperaturaMedia",FloatType(),True)
      .add("CertitudeTempMedia",FloatType(),True)
      .add("País",StringType(),True)
)

df_spark = spark.createDataFrame(df, schema = esquema)

df_spark.show(5)
df_spark.printSchema()

Criação de backup do data frame pyspark


#backup do DF original de PySpark
df_spark_backup = df_spark.alias('df_spark_backup')

Criação da coluna ano utilizando a função substring, a qual possibilita seccionar a data em ano, mês e dia.

#uma coluna com nome 'Ano' é criada a partir da função substring que tem como parâmetro a coluna Data, a posição dos elementos dos valores a serem obtidos e a definição do tipo do valor com a utilização da função cast.
df_spark = df_spark.withColumn('Ano', F.substring(F.col('Data'), 1, 4).cast('Integer'))

df_spark.show(5)

  Criação de um backup do data frame

#backup2
df_spark_backup2 = df_spark.alias('df_spark_backup2')




Eliminação a coluna data

df_spark = df_spark.drop('Data')

df_spark.show(5)
df_spark.printSchema()

Considerar somente linhas a partir do ano de 1900

df_spark = df_spark.where(df_spark.Ano > 1899)

df_spark.show(20)

Eliminação de linhas referentes ao território da Antártica

df_spark = df_spark.where(df_spark.País != 'Antarctica')

Agrupamento de Países por ano calculando a temperatura média anual. Utilizou-se de funções agregadas para esta transformação. Os países foram agrupados (groupBy), em seguida também foram agrupados os valores de temperatura média de cada ano e em seguida submetidos ao cálculo de média (avg). Por o tratamento foi ordenado pelo nome dos países em ordem alfabética e ano em ordem crescente (orderby).


#funções agregadas
df_spark2 = (
    df_spark.groupBy(F.col('País'), F.col('Ano')).avg('TemperaturaMedia').orderBy('País', 'Ano')
)

df_spark2.show(2002)

Renomear coluna avg(TemperaturaMedia)

df_spark2 = df_spark2.withColumnRenamed('avg(TemperaturaMedia)', 'TemperaturaMediaAno')

Eliminando linhas referentes ao ano de 2013, o qual não contém alguns valores e retorna sempre a valores NaN

df_spark2 = df_spark2.where(df_spark.Ano != 2013)

df_spark2.show(300)

A célula abaixo é responsável pela criação da coluna DiferencaTemp, a qual é preenchida com a função de janela 'lag', que preenche cada elemento fazendo a diferença da Temperatura média do ano seguinte em relação ao ano anterior.

lag_window = Window.partitionBy('País').orderBy('País', 'Ano')
#criação do que chamamos de window, que é uma partição dos dados a qual será submetida ao uso da função 'lag' para criação da coluna de DiferencaTemp

df_spark3 = (
        df_spark2.select('País', 'Ano', 'TemperaturaMediaAno')
        .withColumn('DiferencaTemp', F.col('TemperaturaMediaAno') - F.lag('TemperaturaMediaAno')
        .over(lag_window))
)

df_spark3.show()

df_spark3.show(2000)

# Conferir a variação em um país, nesse caso no Iraque

df_spark3.where(df_spark3.País == 'Iraq').show(115)

df_spark3.show(115)

df_spark3.printSchema()

Definição de função, para poder salvar o arquivo pyspark diretamente para o Bucket/Data Lake, utilizando como intermédio o ambiente do drive

#Definição de função, para poder salvar o arquivo pyspark diretamente para o Bucket/Data Lake.

def upload_blob(bucket_name, source_file_name, destination_blob_name):
    """Uploads a file to the bucket."""
    # The ID of your GCS bucket
    # bucket_name = "your-bucket-name"
    # The path to your file to upload
    # source_file_name = "local/path/to/file"
    # The ID of your GCS object
    # destination_blob_name = "storage-object-name"

    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)

    blob.upload_from_filename(source_file_name)

    print("File {} uploaded to {}."
         .format(source_file_name, destination_blob_name))

Arquivo salvo no Bucket/Data Lake:

upload_blob("projeto-final-bucket-g5", "/content/drive/MyDrive/Aluno Luquinha/Programacao/SoulCode Academy/Projetos/Projeto Final – Grupo 5/Temp_media_spark.csv/df_tempmedia_spark_tratado.csv", "saida/df_tempmedia_pyspark_final.csv")
